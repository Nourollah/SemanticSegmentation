{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown <center><h2>Author: AmirMasoud Nourollah</h2></center><br>\n",
    "#@markdown <center><h3>Image Segmentation Using MMSegmentation Toolbox</h3></center><br>\n",
    "\n",
    "class Argo:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "cfg_argo = Argo()\n",
    "\n",
    "#@markdown <center><h3>Train Settings</h3></center><br>\n",
    "\n",
    "notes = \"Provide Image Segmentation Using MMSegmentation\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['notes'] = notes\n",
    "\n",
    "name_suffix = \"PSPNet_TS900_LR0.0001_BS8_AugTrue_E100\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['name_suffix'] = name_suffix\n",
    "\n",
    "is_epoch_based = True  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['is_epoch_based'] = is_epoch_based\n",
    "\n",
    "train_loop_method = \"EpochBasedRunner\"  #@param [\"EpochBasedRunner\", \"IterBasedRunner\"]\n",
    "vars(cfg_argo)['train_loop_method'] = train_loop_method\n",
    "\n",
    "max_epoch_or_iter = 100  #@param {type:\"number\"}\n",
    "vars(cfg_argo)['max_epoch_or_iter'] = max_epoch_or_iter\n",
    "\n",
    "validation_step = 5  #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "vars(cfg_argo)['validation_step'] = validation_step\n",
    "\n",
    "log_per_epoch_or_iter = 5  #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "vars(cfg_argo)['log_per_epoch_or_iter'] = log_per_epoch_or_iter\n",
    "\n",
    "checkpoints_step_per_epoch_or_iter = 10  #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "vars(cfg_argo)['checkpoints_step_per_epoch_or_iter'] = checkpoints_step_per_epoch_or_iter\n",
    "\n",
    "batch_size_per_gpu = 8  #@param {type:\"number\"}\n",
    "vars(cfg_argo)['batch_size_per_gpu'] = batch_size_per_gpu\n",
    "\n",
    "learning_rate = 0.0001  #@param {type:\"number\"}\n",
    "vars(cfg_argo)['learning_rate'] = learning_rate\n",
    "\n",
    "num_worker_per_gpu = 2  #@param {type:\"slider\", min:0, max:128, step:1}\n",
    "vars(cfg_argo)['num_worker_per_gpu'] = num_worker_per_gpu\n",
    "\n",
    "sample_reduction = 'none'  #@param [\"none\", \"mean\", \"sum\"]\n",
    "vars(cfg_argo)['sample_reduction'] = sample_reduction\n",
    "\n",
    "model = \"pspnet\"  #@param [\"pspnet\", \"deeplabv3plus\", \"swin\", \"vit\", \"twins\"]\n",
    "vars(cfg_argo)['model'] = model\n",
    "\n",
    "config_file_path = 'configs/pspnet/pspnet_r50-d8_512x512_4x4_160k_coco-stuff164k.py'  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['config_file_path'] = config_file_path\n",
    "\n",
    "metrics = \"mIoU,mDice\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['metrics'] = metrics\n",
    "\n",
    "dataset = \"Multi Class\"  #@param [\"Multi Class\", \"Binary Simple\", \"Binary Complex\"]\n",
    "vars(cfg_argo)['dataset'] = dataset\n",
    "\n",
    "num_classes = 8  #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "vars(cfg_argo)['num_classes'] = num_classes\n",
    "vars(cfg_argo)['classes_map_num'] = list(range(num_classes))\n",
    "\n",
    "#@markdown <center><h5 style=\"colour: green\">Change colors is not supported automatically, Please change from Code</h5></center><br>\n",
    "\n",
    "colors = [(0, 0, 0),\n",
    "          (137, 137, 255),\n",
    "          (173, 173, 173),\n",
    "          (213, 44, 44),\n",
    "          (25, 133, 191),\n",
    "          (211, 208, 34),\n",
    "          (255, 20, 147),\n",
    "          (37, 162, 20),]\n",
    "vars(cfg_argo)['colors'] = colors\n",
    "\n",
    "#@markdown <center><h4>Write class name in string format like: \"cat,dog,mouse,lion\"</h4></center><br>\n",
    "classes_name = \"background,Soma,Secondary,Axon,Dendrite,Primary,Tertiary,Dendrite_primary\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['classes_name'] = classes_name.split(\",\")\n",
    "\n",
    "combine_loss = True  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['combine_loss'] = combine_loss\n",
    "\n",
    "first_loss_name = \"loss_ce\"  #@param [\"loss_ce\", \"bce\", \"loss_dice\", \"loss_focal\", \"loss_lovasz\"]\n",
    "vars(cfg_argo)['first_loss_name'] = first_loss_name\n",
    "\n",
    "first_loss_type = \"DiceLoss\"  #@param [\"CrossEntropyLoss\", \"DiceLoss\", \"FocalLoss\", \"LovaszLoss\"]\n",
    "vars(cfg_argo)['first_loss_type'] = first_loss_type\n",
    "\n",
    "first_loss_weight = 1 #@param {type:\"slider\", min:1, max:4, step:1}\n",
    "vars(cfg_argo)['first_loss_weight'] = first_loss_weight\n",
    "\n",
    "second_loss_name = \"loss_dice\"  #@param [\"loss_ce\", \"bce\", \"loss_dice\", \"loss_focal\", \"loss_lovasz\"]\n",
    "vars(cfg_argo)['second_loss_name'] = second_loss_name\n",
    "\n",
    "second_loss_type = \"CrossEntropyLoss\"  #@param [\"CrossEntropyLoss\", \"DiceLoss\", \"FocalLoss\", \"LovaszLoss\"]\n",
    "vars(cfg_argo)['second_loss_type'] = second_loss_type\n",
    "\n",
    "second_loss_weight = 1 #@param {type:\"slider\", min:1, max:4, step:1}\n",
    "vars(cfg_argo)['second_loss_weight'] = second_loss_weight\n",
    "\n",
    "normalize_mean = [123.675, 116.28, 103.53]  #@param\n",
    "vars(cfg_argo)['normalize_mean'] = normalize_mean\n",
    "\n",
    "normalize_std = [58.395, 57.12, 57.375]  #@param\n",
    "vars(cfg_argo)['normalize_std'] = normalize_std\n",
    "\n",
    "device = \"cuda\"  #@param [\"cpu\", \"cuda\", \"cuda:0\", \"cuda:1\", \"cuda:2\", \"cuda:3\", \"cuda:4\", \"cuda:5\", \"cuda:6\", \"cuda:7\", \"multi_gpu\"]\n",
    "vars(cfg_argo)['device'] = device\n",
    "\n",
    "is_multi_gpu = False  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['is_multi_gpu'] = is_multi_gpu\n",
    "\n",
    "gpu_number = 1  #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "\n",
    "resize = False  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['resize'] = resize\n",
    "\n",
    "image_height = 512  #@param {type:\"integer\"}\n",
    "vars(cfg_argo)['image_height'] = image_height\n",
    "\n",
    "image_weight = 512  #@param {type:\"integer\"}\n",
    "vars(cfg_argo)['image_weight'] = image_weight\n",
    "\n",
    "#@markdown <center><h3>Paths Settings</h3></center><br>\n",
    "\n",
    "dataset_path = \"/content/drive/MyDrive/NeuronDataset/\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['dataset_path'] = dataset_path\n",
    "\n",
    "dataset_type = \"ADE20KDataset\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['dataset_type'] = dataset_type\n",
    "\n",
    "train_images_path = \"images/train\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['train_images_path'] = train_images_path\n",
    "\n",
    "train_masks_path = \"annotations/train\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['train_masks_path'] = train_masks_path\n",
    "\n",
    "validation_images_path = \"images/validation\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['validation_images_path'] = validation_images_path\n",
    "\n",
    "validation_masks_path = \"annotations/validation\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['validation_masks_path'] = validation_masks_path\n",
    "\n",
    "test_images_path = \"images/test\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['test_images_path'] = test_images_path\n",
    "\n",
    "test_masks_path = \"annotations/test\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['test_masks_path'] = test_masks_path\n",
    "\n",
    "result_path = \"test/result\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['result_path'] = result_path\n",
    "\n",
    "#@markdown <center><h3>Logs & Wandb</h3></center><br>\n",
    "\n",
    "tensorboard_log = True  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['tensorboard_log'] = tensorboard_log\n",
    "\n",
    "wandb_log = True  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['wandb_log'] = wandb_log\n",
    "\n",
    "wandb_entity = \"\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['wandb_entity'] = wandb_entity\n",
    "\n",
    "wandb_project_name = \"\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['wandb_project_name'] = wandb_project_name\n",
    "\n",
    "\n",
    "def wget(url: str,\n",
    "         file_path: str) -> bool:\n",
    "    from tqdm import tqdm\n",
    "    import requests\n",
    "    import os\n",
    "    if not os.path.isfile(file_path):\n",
    "        try:\n",
    "            res = requests.get(url,\n",
    "                               stream=True)\n",
    "            with open(file_path,\n",
    "                      \"wb\") as file_handler:\n",
    "                for data in tqdm(res.iter_content()):\n",
    "                    file_handler.write(data)\n",
    "\n",
    "            return True\n",
    "        except requests.HTTPError:\n",
    "            return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#@markdown <center><h3>Pretrain Config</h3></center><br>\n",
    "\n",
    "work_directory = \"/content/drive/MyDrive/checkpoints/segmentor/full_segmentor/pspnet\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['work_directory'] = work_directory\n",
    "\n",
    "use_pretrain = True  #@param {type:\"boolean\"}\n",
    "vars(cfg_argo)['use_pretrain'] = use_pretrain\n",
    "\n",
    "pretrain_model_mod = \"URL\"  #@param [\"URL\", \"PATH\"]\n",
    "vars(cfg_argo)['pretrain_model_mod'] = pretrain_model_mod\n",
    "\n",
    "pretrain_path = \"\"  #@param {type:\"string\"}\n",
    "vars(cfg_argo)['pretrain_path'] = pretrain_path\n",
    "\n",
    "pretrain_checkpoint_path = \"\" #@param {type:\"string\"}\n",
    "vars(cfg_argo)['pretrain_checkpoint_path'] = pretrain_checkpoint_path\n",
    "\n",
    "if pretrain_model_mod == \"URL\":\n",
    "    import os\n",
    "\n",
    "    model_file_name_and_path = os.path.join(work_directory,\n",
    "                                            pretrain_path.split(\"/\")[-1])\n",
    "    download = wget(pretrain_path,\n",
    "                    model_file_name_and_path)\n",
    "    pretrain_path = (None, model_file_name_and_path)[download]\n",
    "    vars(cfg_argo)['pretrain_path'] = pretrain_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMOxLYZ_oUg9",
    "outputId": "b3990b79-900f-4f58-ef62-e5a6ac7477ad"
   },
   "outputs": [],
   "source": [
    "# Check nvcc version\n",
    "! nvcc -V\n",
    "# Check GCC version\n",
    "! gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTf5DpRXV60G",
    "outputId": "088a303f-c5e1-4834-a950-f8afb315bf6e"
   },
   "outputs": [],
   "source": [
    "#@title install dependencies: PyTorch, MMCV, MMSegmentation\n",
    "# install dependencies: (use cu113 because colab has CUDA 11.3)\n",
    "! pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# install mmcv-full thus we could use CUDA operators\n",
    "! pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n",
    "\n",
    "# install wandb for wandb hook\n",
    "! pip install wandb\n",
    "\n",
    "# Install mmdetection\n",
    "! rm -rf mmsegmentation\n",
    "! git clone https://github.com/open-mmlab/mmsegmentation.git\n",
    "% cd mmsegmentation\n",
    "\n",
    "! pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCwAZBYtoqIU",
    "outputId": "56a88c63-270b-444b-98b7-cf8fac7d638c"
   },
   "outputs": [],
   "source": [
    "from mmcv import collect_env\n",
    "\n",
    "collect_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "BAEdYrwjVOuN"
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.cnn.utils import revert_sync_batchnorm\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor, inference_segmentor, set_random_seed\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as m_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSGZIOEAoNZt",
    "outputId": "9a2e3750-4bb1-4010-ea1b-b5d6bc6f59b7"
   },
   "outputs": [],
   "source": [
    "#@title Mount google drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmXzHNcwVOuV"
   },
   "outputs": [],
   "source": [
    "class SegmentationModel:\n",
    "    def __init__(self,\n",
    "                 argo: Argo) -> None:\n",
    "        self.args = argo\n",
    "        self.cfg = None\n",
    "        self.model = None\n",
    "        self.register_dataset = False\n",
    "\n",
    "\n",
    "    def prepare_config(self) -> None:\n",
    "        cfg = Config.fromfile(self.args.config_file_path)\n",
    "        # Since we use ony one GPU, BN is used instead of SyncBN\n",
    "        batch_norm_type = \"BN\" if self.args.gpu_number else \"SyncBN\"\n",
    "        cfg.device = self.args.device\n",
    "        cfg.norm_cfg = dict(type=batch_norm_type,\n",
    "                            requires_grad=True)\n",
    "        # cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "        # cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "        cfg.model.decode_head.norm_cfg = dict(type=batch_norm_type,\n",
    "                                              requires_grad=True)\n",
    "        cfg.model.auxiliary_head.norm_cfg = dict(type=batch_norm_type,\n",
    "                                                 requires_grad=True)\n",
    "        # modify num classes of the model in decode/auxiliary head\n",
    "        cfg.model.decode_head.num_classes = self.args.num_classes\n",
    "        cfg.model.auxiliary_head.num_classes = self.args.num_classes\n",
    "        cfg.dataset_type = self.args.dataset_type\n",
    "        cfg.data_root = self.args.dataset_path\n",
    "        cfg.img_norm_cfg = dict(mean=self.args.normalize_mean,\n",
    "                                std=self.args.normalize_std,\n",
    "                                to_rgb=True)\n",
    "        cfg.crop_size = (self.args.image_height // 2,\n",
    "                         self.args.image_width // 2)\n",
    "        cfg.train_pipeline = [\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='LoadAnnotations'),  # ,reduce_zero_label=False),\n",
    "            dict(type='Resize',\n",
    "                 img_scale=(self.args.image_height,\n",
    "                            self.args.image_width),\n",
    "                 ratio_range=(0.5,\n",
    "                              2.0)),\n",
    "            dict(type='RandomCrop',\n",
    "                 crop_size=cfg.crop_size,\n",
    "                 cat_max_ratio=0.75),\n",
    "            dict(type='RandomFlip',\n",
    "                 flip_ratio=0.5),\n",
    "            dict(type='PhotoMetricDistortion'),\n",
    "            dict(type='Normalize',\n",
    "                 **cfg.img_norm_cfg),\n",
    "            dict(type='Pad',\n",
    "                 size=cfg.crop_size,\n",
    "                 pad_val=0,\n",
    "                 seg_pad_val=255),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect',\n",
    "                 keys=['img', 'gt_semantic_seg']),\n",
    "        ]\n",
    "        cfg.test_pipeline = [\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='MultiScaleFlipAug',\n",
    "                 img_scale=(self.args.image_height,\n",
    "                            self.args.image_width),\n",
    "                 # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "                 flip=False,\n",
    "                 transforms=[\n",
    "                     dict(type='Resize',\n",
    "                          keep_ratio=True),\n",
    "                     dict(type='RandomFlip'),\n",
    "                     dict(type='Normalize',\n",
    "                          **cfg.img_norm_cfg),\n",
    "                     dict(type='ImageToTensor',\n",
    "                          keys=['img']),\n",
    "                     dict(type='Collect',\n",
    "                          keys=['img']),\n",
    "                 ])\n",
    "        ]\n",
    "        cfg.validation_pipline = cfg.test_pipeline\n",
    "\n",
    "        cfg.data.samples_per_gpu = self.args.batch_size_per_gpu\n",
    "        cfg.data.workers_per_gpu = self.args.num_worker_per_gpu\n",
    "\n",
    "        cfg.data.train.type = cfg.dataset_type\n",
    "        cfg.data.train.data_root = cfg.data_root\n",
    "        cfg.data.train.img_dir = self.args.train_images_path\n",
    "        cfg.data.train.ann_dir = self.args.train_masks_path\n",
    "        cfg.data.train.pipeline = cfg.train_pipeline\n",
    "\n",
    "\n",
    "        cfg.data.val.type = cfg.dataset_type\n",
    "        cfg.data.val.data_root = cfg.data_root\n",
    "        cfg.data.val.img_dir = self.args.validation_images_path\n",
    "        cfg.data.val.ann_dir = self.args.validation_masks_path\n",
    "        cfg.data.val.pipeline = cfg.validation_pipline\n",
    "\n",
    "\n",
    "        cfg.data.test.type = cfg.dataset_type\n",
    "        cfg.data.test.data_root = cfg.data_root\n",
    "        cfg.data.test.img_dir = self.args.test_images_path\n",
    "        cfg.data.test.ann_dir = self.args.test_masks_path\n",
    "        cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "        cfg.load_from = None\n",
    "        # Set up working dir to save files and logs.\n",
    "        if self.args.combine_loss:\n",
    "            cfg.model.decode_head.loss_decode = dict(type=self.args.first_loss_type,\n",
    "                                                     loss_name=self.args.first_loss_name,\n",
    "                                                     loss_weight=self.args.first_loss_weight,\n",
    "                                                     reduction='none'), dict(type=self.args.second_loss_type,\n",
    "                                                                             loss_name=self.args.second_loss_name,\n",
    "                                                                             loss_weight=self.args.second_loss_weight)\n",
    "            cfg.model.auxiliary_head.loss_decode = dict(type=self.args.first_loss_type,\n",
    "                                                        loss_name=self.args.first_loss_name,\n",
    "                                                        loss_weight=self.args.first_loss_weight,\n",
    "                                                        reduction='none'), dict(type=self.args.second_loss_type,\n",
    "                                                                                loss_name=self.args.second_loss_name,\n",
    "                                                                                loss_weight=self.args.second_loss_weight)\n",
    "        else:\n",
    "            cfg.model.decode_head.loss_decode = dict(type=self.args.first_loss_type,\n",
    "                                                     loss_name=self.args.first_loss_name,\n",
    "                                                     loss_weight=self.args.first_loss_weight,\n",
    "                                                     reduction='none'),\n",
    "\n",
    "            cfg.model.auxiliary_head.loss_decode = dict(type=self.args.first_loss_type,\n",
    "                                                        loss_name=self.args.first_loss_name,\n",
    "                                                        loss_weight=self.args.first_loss_weight,\n",
    "                                                        reduction='none')\n",
    "\n",
    "        if self.args.train_loop_method == \"EpochBasedRunner\":\n",
    "            cfg.runner = dict(\n",
    "                type='EpochBasedRunner',\n",
    "                max_epochs=self.args.max_epoch_or_iter)\n",
    "        else:\n",
    "            cfg.runner = dict(\n",
    "                type='IterBasedRunner',\n",
    "                max_iter=self.args.max_epoch_or_iter)\n",
    "        if self.args.wandb_log:\n",
    "            cfg.log_config = dict(\n",
    "                interval=self.args.log_per_epoch_or_iter,\n",
    "                hooks=[\n",
    "                    dict(type='TensorboardLoggerHook', by_epoch=self.args.is_epoch_based),\n",
    "                    dict(type='TextLoggerHook', by_epoch=self.args.is_epoch_based),\n",
    "                    dict(type='WandbLoggerHook', by_epoch=self.args.is_epoch_based,\n",
    "                        init_kwargs={'entity': self.args.wandb_entity,\n",
    "                                    'project': self.args.wandb_project_name,\n",
    "                                    'config': self.args.__dict__})\n",
    "                ])\n",
    "        else:\n",
    "            cfg.log_config = dict(\n",
    "                interval=self.args.log_per_epoch_or_iter,\n",
    "                hooks=[\n",
    "                    dict(type='TensorboardLoggerHook', by_epoch=self.args.is_epoch_based),\n",
    "                    dict(type='TextLoggerHook', by_epoch=self.args.is_epoch_based),\n",
    "                ])\n",
    "        cfg.evaluation = dict(\n",
    "            interval=self.args.validation_step,\n",
    "            metric=self.args.metrics)\n",
    "        cfg.checkpoint_config = dict(\n",
    "            by_epoch=self.args.is_epoch_based,\n",
    "            interval=self.args.checkpoints_step_per_epoch_or_iter)\n",
    "        cfg.optimizer.lr = self.args.learning_rate\n",
    "        cfg.optimizer.paramwise_cfg = dict(\n",
    "            custom_keys={\n",
    "                'head': dict(lr_mult=100.)})\n",
    "        cfg.work_dir = self.args.work_directory\n",
    "\n",
    "        # Set seed to facilitate reproducing the result\n",
    "        cfg.seed = 0\n",
    "        set_random_seed(0, deterministic=False)\n",
    "        cfg.gpu_ids = range(self.args.gpu_number)\n",
    "        if self.args.use_pretrain:\n",
    "            cfg.load_from = self.args.pretrain_path\n",
    "        else:\n",
    "            cfg.model.pretrained = None\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def init_model(self) -> None:\n",
    "        self.model = build_segmentor(self.cfg.model,\n",
    "                                     train_cfg=self.cfg.get('train_cfg'),\n",
    "                                     test_cfg=self.cfg.get('test_cfg'))\n",
    "        self.model.CLASSES = num_classes\n",
    "        self.model.PALETTE = self.args.classes_map_num\n",
    "\n",
    "    def train_model(self) -> None:\n",
    "        datasets = [build_dataset(self.cfg.data.train)]\n",
    "        mmcv.mkdir_or_exist(os.path.abspath(self.cfg.work_dir))\n",
    "        train_segmentor(self.model,\n",
    "                        datasets,\n",
    "                        self.cfg,\n",
    "                        distributed=False,\n",
    "                        validate=True,\n",
    "                        meta={})\n",
    "\n",
    "    def test_model(self,\n",
    "                   pallete: list = None,\n",
    "                   checkpoint: str = None,\n",
    "                   gt_path: str = None,\n",
    "                   img_direction: str = None) -> None:\n",
    "\n",
    "        pallete = self.args.colors if pallete is None else pallete\n",
    "        checkpoint = self.args.pretrain_checkpoint_path if checkpoint is None else checkpoint\n",
    "        gt_path = self.args.test_masks_path if gt_path is None else gt_path\n",
    "        img_direction = os.path.join(self.args.dataset_path, self.args.test_images_path) if img_direction is None else img_direction\n",
    "\n",
    "        cfg = Config.fromfile(self.args.config_file_path)\n",
    "        cfg.model.train_cfg = None\n",
    "        cfg.model.decode_head.num_classes = self.args.num_classes\n",
    "        cfg.model.auxiliary_head.num_classes = self.args.num_classes\n",
    "        model = build_segmentor(\n",
    "            cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "        model.CLASSES = self.args.classes_name\n",
    "        model.PALETTE = pallete\n",
    "        model.pretrained = None\n",
    "        checkpoint = load_checkpoint(model, checkpoint, map_location=self.args.device)\n",
    "        model = revert_sync_batchnorm(model)\n",
    "        model.cfg = cfg\n",
    "        model.to(self.args.device)\n",
    "        model.eval()\n",
    "        for file_name in os.listdir(img_direction):\n",
    "            image = mmcv.imread(os.path.join(img_direction, file_name))\n",
    "            result = inference_segmentor(model, image)\n",
    "            self.prepare_result(image, result[0], pallete, classes, self.args.result_path, file_name, gt_path, self.args.name_suffix)\n",
    "\n",
    "    @staticmethod\n",
    "    def color_img(seg_map, colors) -> np.ndarray:\n",
    "        color_seg = np.zeros((seg_map.shape[0], seg_map.shape[1], 3), dtype=np.uint8)\n",
    "        for label, color_map in enumerate(colors):\n",
    "            color_seg[seg_map == label, :] = color_map\n",
    "        return color_seg\n",
    "\n",
    "    def prepare_result(self,\n",
    "                       img: np.ndarray,\n",
    "                       res: np.ndarray,\n",
    "                       colors: list,\n",
    "                       labels: list,\n",
    "                       path: str,\n",
    "                       file_name: str,\n",
    "                       gt_path: str,\n",
    "                       experiment_name: str) -> None:\n",
    "        print(f\"segment shape: {res.shape}\")\n",
    "        res = self.color_img(res,\n",
    "                             colors)\n",
    "        mmcv.imwrite(mmcv.rgb2bgr(res),\n",
    "                     os.path.join(path,\n",
    "                                  f\"{experiment_name}{'_result_'}{file_name}\"))\n",
    "        fig = plt.figure(figsize=(16, 16))\n",
    "        fig.suptitle(experiment_name, fontsize=16)\n",
    "        ax = fig.add_subplot(1, 3, 1)\n",
    "        plt.imshow(res)\n",
    "        ax.set_title(\"Prediction\")\n",
    "        ax = fig.add_subplot(1, 3, 2)\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(\"Image\")\n",
    "        print(f\"Result of {path.split('/')[-1].split('.')[0]}.png:\")\n",
    "        gt = cv2.cvtColor(\n",
    "            mmcv.imread(os.path.join(gt_path,\n",
    "                                     f\"{path.split('/')[-1].split('.')[0]}.png\")),\n",
    "            cv2.COLOR_BGR2RGB)\n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(gt)\n",
    "        ax.set_title(\"Ground-truth\")\n",
    "        patches = [m_patches.Patch(color=np.array(colors[i]) / 255.,\n",
    "                                   label=labels[i]) for i in range(len(colors))]\n",
    "        # put those patched as legend-handles into the legend\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize='large')\n",
    "        plt.savefig(os.path.join(path,\n",
    "                                 f\"{experiment_name}{'_subplot_'}{file_name}\"))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zk4DhqghVOuX"
   },
   "outputs": [],
   "source": [
    "Network = SegmentationModel(argo=cfg_argo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk1PqoMYvLJw"
   },
   "outputs": [],
   "source": [
    "Network.prepare_config(cfg_argo.config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gorv5IH9vMjX",
    "outputId": "dd1379e7-e498-4604-cb99-5a523e2fe0fa"
   },
   "outputs": [],
   "source": [
    "Network.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "Fbhopp7T0i1_",
    "outputId": "d29d84ad-06f7-4850-f793-c13687bdb15d"
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "dist.init_process_group(backend='nccl', init_method='tcp://localhost:23456', rank=0, world_size=1)\n",
    "ignore_define = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TZrWzmLe2dAf",
    "outputId": "44444eb8-ea87-4de9-a800-b88154622ae8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load tensorboard in colab\n",
    "% load_ext tensorboard\n",
    "\n",
    "# see curves in tensorboard\n",
    "% tensorboard --logdir/content/drive/MyDrive/checkpoints/segmentor/full_segmentor/semantic_pspnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Network.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Network.test_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NeuronSemanticSegmentation.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}